{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7f1057-c4d1-4ff5-83fd-2c124d500d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os, sys, time\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.YParams import YParams\n",
    "from ruamel.yaml import YAML\n",
    "# torch optimizers and lr schedulers\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c888ef6-4478-430d-8fb7-96bee2c54690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some dummy model\n",
    "import torch.nn as nn\n",
    "\n",
    "def my_conv(in_channels, out_channels, kernel_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, padding='same'),\n",
    "        nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "           \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=2, depth=5, hidden_dim=64, kernel_size=5, dropout=0.):\n",
    "        super(CNN, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.dropout = dropout\n",
    "        self.conv_in = my_conv(in_channels, hidden_dim, kernel_size)\n",
    "        self.conv_hidden = nn.ModuleList([my_conv(hidden_dim, hidden_dim, kernel_size) for _ in range(self.depth-2)]) \n",
    "        self.conv_out = my_conv(hidden_dim, out_channels, kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        for layer in self.conv_hidden:\n",
    "            x = layer(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "       \n",
    "def simple_cnn(params, **kwargs):\n",
    "    model = CNN(in_channels=params.in_chan, out_channels=params.out_chan, depth=params.depth, hidden_dim=64,\n",
    "                kernel_size=3, **kwargs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9772dfbb-e6ae-4d5f-9739-700e4f99db44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some dummy dataloader\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# see: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "def get_data_loader(params, location, train=True):\n",
    "    dataset = TestDataSet(params, location)\n",
    "    if train:\n",
    "        batch_size = params.local_batch_size\n",
    "    else:\n",
    "        batch_size = params.local_valid_batch_size\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=int(batch_size),\n",
    "                            num_workers=params.num_data_workers,\n",
    "                            shuffle=True,\n",
    "                            sampler=None,\n",
    "                            drop_last=True,\n",
    "                            pin_memory=torch.cuda.is_available())\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class TestDataSet(Dataset):\n",
    "    def __init__(self, params, location):\n",
    "        self.params = params\n",
    "        self.location = location # not used, but input data loc goes here\n",
    "        self.n_samples = 128\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ''' just return random tensors '''\n",
    "        X = torch.rand((1,128,128))\n",
    "        y = torch.rand((1,128,128))\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1803673-c8cf-40d4-a3ed-619589095210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Configuration ------------------\n",
      "Configuration file: /global/u2/s/shas1693/codes/nersc-dl-multigpu/configs/default.yaml\n",
      "Configuration name: default\n",
      "num_data_workers 1\n",
      "in_chan 1\n",
      "out_chan 1\n",
      "depth 5\n",
      "lr 0.001\n",
      "max_epochs 25\n",
      "max_cosine_lr_epochs 25\n",
      "batch_size 32\n",
      "valid_batch_size 32\n",
      "log_to_screen True\n",
      "save_checkpoint True\n",
      "train_path \n",
      "val_path \n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get hyperparams and config details\n",
    "config_name = 'default'\n",
    "params = YParams(os.path.abspath('./configs/default.yaml'), config_name)\n",
    "params.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4fb6b08-466e-4e0c-a5e4-d4ed9cc96b63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# where to run\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    device = torch.cuda.current_device()\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0dfd98-df1d-4106-a25d-f5ffeff858da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "# batch sizes for training and validation (local batch sizes are the same on single GPU)\n",
    "params['global_batch_size'] = params.batch_size\n",
    "params['local_batch_size'] = params.batch_size\n",
    "params['global_valid_batch_size'] = params.valid_batch_size\n",
    "params['local_valid_batch_size'] = params.valid_batch_size\n",
    "\n",
    "# get the dataloaders\n",
    "train_data_loader = get_data_loader(params, params.train_path, train=True)\n",
    "val_data_loader = get_data_loader(params, params.val_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84b2db14-c00b-4e30-99b7-cbbe74a96d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the model and training details\n",
    "model = simple_cnn(params).to(device) # send model wts to GPU\n",
    "\n",
    "# set an optimizer and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=params.lr)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=params.max_cosine_lr_epochs)\n",
    "\n",
    "# set loss functions\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b07f493-733c-4f9b-a72f-cee2bf6d7f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for epoch 1 is 7.895143508911133 sec; with 7.710684061050415/0.1817774772644043 in tr/val\n",
      "Loss = 0.2027476280927658, Val loss = 0.14298033714294434\n",
      "Time taken for epoch 2 is 0.41819047927856445 sec; with 0.23258662223815918/0.18485164642333984 in tr/val\n",
      "Loss = 0.10877930372953415, Val loss = 0.10980162024497986\n",
      "Time taken for epoch 3 is 0.39698266983032227 sec; with 0.2169637680053711/0.17949652671813965 in tr/val\n",
      "Loss = 0.09730541706085205, Val loss = 0.0945519506931305\n",
      "Time taken for epoch 4 is 0.41175198554992676 sec; with 0.23145174980163574/0.17969727516174316 in tr/val\n",
      "Loss = 0.09379316866397858, Val loss = 0.0875803604722023\n",
      "Time taken for epoch 5 is 0.41367506980895996 sec; with 0.23390460014343262/0.17927885055541992 in tr/val\n",
      "Loss = 0.09104160219430923, Val loss = 0.08907153457403183\n",
      "Time taken for epoch 6 is 0.4241926670074463 sec; with 0.23750066757202148/0.18609142303466797 in tr/val\n",
      "Loss = 0.08819828927516937, Val loss = 0.08918419480323792\n",
      "Time taken for epoch 7 is 0.4461843967437744 sec; with 0.2330164909362793/0.21232151985168457 in tr/val\n",
      "Loss = 0.08744361251592636, Val loss = 0.0872969925403595\n",
      "Time taken for epoch 8 is 0.4034864902496338 sec; with 0.23020195960998535/0.17252206802368164 in tr/val\n",
      "Loss = 0.08717404305934906, Val loss = 0.08624240756034851\n",
      "Time taken for epoch 9 is 0.42777538299560547 sec; with 0.24864816665649414/0.17826533317565918 in tr/val\n",
      "Loss = 0.08660013973712921, Val loss = 0.08641252666711807\n",
      "Time taken for epoch 10 is 0.4190492630004883 sec; with 0.23655009269714355/0.18163037300109863 in tr/val\n",
      "Loss = 0.08640880137681961, Val loss = 0.08648731559515\n",
      "Time taken for epoch 11 is 0.44428563117980957 sec; with 0.25449490547180176/0.18894243240356445 in tr/val\n",
      "Loss = 0.0861857607960701, Val loss = 0.08622299134731293\n",
      "Time taken for epoch 12 is 0.417208194732666 sec; with 0.23541665077209473/0.18093562126159668 in tr/val\n",
      "Loss = 0.08604744076728821, Val loss = 0.08612579852342606\n",
      "Time taken for epoch 13 is 0.4104790687561035 sec; with 0.22628283500671387/0.1835765838623047 in tr/val\n",
      "Loss = 0.08597422391176224, Val loss = 0.08597975224256516\n",
      "Time taken for epoch 14 is 0.38961100578308105 sec; with 0.2125718593597412/0.17643094062805176 in tr/val\n",
      "Loss = 0.08584953099489212, Val loss = 0.085734523832798\n",
      "Time taken for epoch 15 is 0.4043300151824951 sec; with 0.2268538475036621/0.17669081687927246 in tr/val\n",
      "Loss = 0.08584825694561005, Val loss = 0.08583442121744156\n",
      "Time taken for epoch 16 is 0.4226188659667969 sec; with 0.24156785011291504/0.18029284477233887 in tr/val\n",
      "Loss = 0.08565495908260345, Val loss = 0.08562316745519638\n",
      "Time taken for epoch 17 is 0.4294111728668213 sec; with 0.24031949043273926/0.18830370903015137 in tr/val\n",
      "Loss = 0.08556593954563141, Val loss = 0.08554384112358093\n",
      "Time taken for epoch 18 is 0.43863916397094727 sec; with 0.2473766803741455/0.18986749649047852 in tr/val\n",
      "Loss = 0.0855472981929779, Val loss = 0.08546007424592972\n",
      "Time taken for epoch 19 is 0.4244081974029541 sec; with 0.23759794235229492/0.1856095790863037 in tr/val\n",
      "Loss = 0.08543917536735535, Val loss = 0.08554139733314514\n",
      "Time taken for epoch 20 is 0.4663429260253906 sec; with 0.28393077850341797/0.1813218593597412 in tr/val\n",
      "Loss = 0.0854569673538208, Val loss = 0.08543547987937927\n",
      "Time taken for epoch 21 is 0.4147214889526367 sec; with 0.2298421859741211/0.1840827465057373 in tr/val\n",
      "Loss = 0.08542025834321976, Val loss = 0.08531825989484787\n",
      "Time taken for epoch 22 is 0.41306138038635254 sec; with 0.2315232753753662/0.1803140640258789 in tr/val\n",
      "Loss = 0.08534784615039825, Val loss = 0.08548019081354141\n",
      "Time taken for epoch 23 is 0.4104030132293701 sec; with 0.22930455207824707/0.18039226531982422 in tr/val\n",
      "Loss = 0.08539771288633347, Val loss = 0.08532503992319107\n",
      "Time taken for epoch 24 is 0.41822242736816406 sec; with 0.23495078086853027/0.1824350357055664 in tr/val\n",
      "Loss = 0.08534272015094757, Val loss = 0.08543946593999863\n",
      "Time taken for epoch 25 is 0.4051017761230469 sec; with 0.2194368839263916/0.1848011016845703 in tr/val\n",
      "Loss = 0.08534926176071167, Val loss = 0.08532828092575073\n"
     ]
    }
   ],
   "source": [
    "# train and validate\n",
    "for epoch in range(0, params.max_epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    # training\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    tr_start = time.time()\n",
    "    for i, (inputs, targets) in enumerate(train_data_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # zero grads\n",
    "        model.zero_grad()\n",
    "        # fwd\n",
    "        u = model(inputs)\n",
    "        loss = loss_func(u, targets)\n",
    "        train_loss += loss.detach()\n",
    "        # bwd\n",
    "        loss.backward()\n",
    "        # update\n",
    "        optimizer.step()\n",
    "    tr_time = time.time() - tr_start\n",
    "    train_loss /= len(train_data_loader) # avg train loss\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    val_start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_data_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            u = model(inputs)\n",
    "            loss = loss_func(u, targets)\n",
    "            val_loss += loss.detach()\n",
    "    val_time = time.time() - val_start\n",
    "    val_loss /= len(val_data_loader)\n",
    "\n",
    "    # learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    print('Time taken for epoch {} is {} sec; with {}/{} in tr/val'.format(epoch+1, time.time()-start, tr_time, val_time))\n",
    "    print('Loss = {}, Val loss = {}'.format(train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef10e7-104d-4dab-b1f7-3d7647cbe295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
